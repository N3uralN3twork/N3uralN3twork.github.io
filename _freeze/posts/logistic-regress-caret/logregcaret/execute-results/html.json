{
  "hash": "8e54110b79749c83c1ee5f638ed8fc3c",
  "result": {
    "markdown": "---\ntitle: \"Logistic Regression with caret\"\ndescription: \"A quick notebook on how to create and interpret LR models.\"\nauthor: \"Matthias Quinn\"\ndate: \"10/26/2019\"\ncategories:\n  - code\n  - ML\n  - algorithms\n  - college\nimage: CarrotImage.jpg\nimage-alt: caret in R\n---\n\n\n[Logistic Regression](https://www.r-bloggers.com/evaluating-logistic-regression-models/)\n\n# Goals:\n\n1.  Learn the basics of a logistic regression\n2.  Learn how to implement logistic regression in R with Caret\n\n# Notes:\n\n-   Logistic Regression is suited for categorical response variables and one or more predictor variables.\n-   $Log(Odds) = \\beta1*X1+...\\beta N*Xn$\n-   The log(odds) ratio is $ln[p/(1-p)]$\n-   Predicted probability of an event occurring: $p = 1/(1+\\exp^{-z})$\n\nThis project will be using the *German Credit* dataset from the caret package. Goal is to predict whether a consumer is good or bad for business.\n\n\nThis project will be using the *German Credit* dataset from the caret package. Goal is to predict whether a consumer is good or bad for business.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: ggplot2\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: lattice\n```\n:::\n\n```{.r .cell-code}\nlibrary(readr)\nlibrary(jsonlite)\ndata(\"GermanCredit\")\nmydata <- read_csv(\"https://stats.idre.ucla.edu/stat/data/binary.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 400 Columns: 4\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\ndbl (4): admit, gre, gpa, rank\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nmydata$rank <- factor(mydata$rank)\n```\n:::\n\n\n## Step 1. Split the data into training and test sets\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(12345789)\ninTrain <- createDataPartition(y = GermanCredit$Class, p = 0.6, list = FALSE, )\ntraining <- GermanCredit[inTrain, ]\ntesting  <- GermanCredit[-inTrain, ]\n```\n:::\n\n\nTo create the logistic model, we'll use the *train* function from caret.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlmodel <- train(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,\n                data = training,\n                method = \"glm\",\n                family = \"binomial\")\n```\n:::\n\n\nTo obtain the odds for the coefficients and remove the log:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexp(coef(lmodel$finalModel))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           (Intercept)                    Age          ForeignWorker \n             3.0516947              1.0095028              0.2494196 \n   Property.RealEstate            Housing.Own CreditHistory.Critical \n             1.7752920              1.7580389              2.2363912 \n```\n:::\n:::\n\n\nKeep in mind that you can't just read the coefficients like you would in simple linear regression.\n\nFor example, our model is suggesting that for every one unit increase in *Age*, the **(odds)** of the consumer having good credit increases by a factor of 1.02\n\n95% Confidence Interval for terms:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogistic = glm(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + CreditHistory.Critical,\n                data = training,\n                family = \"binomial\")\n\ncbind(OR = exp(coef(logistic)), exp(confint(logistic)), pValue = (summary(logistic)$coefficients[, 4]))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWaiting for profiling to be done...\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n                              OR      2.5 %     97.5 %       pValue\n(Intercept)            3.0516947 0.74027688 20.9221296 0.1700607984\nAge                    1.0095028 0.99357880  1.0262071 0.2501534852\nForeignWorker          0.2494196 0.03925941  0.8803206 0.0651729645\nProperty.RealEstate    1.7752920 1.15611482  2.7758529 0.0100252083\nHousing.Own            1.7580389 1.18604549  2.6003291 0.0047917432\nCreditHistory.Critical 2.2363912 1.45002355  3.5270854 0.0003723358\n```\n:::\n:::\n\n\nEssentially, if the confidence interval contains 1, it is not very helpful\n\n##Making Predictions: To make predictions, simple use the *predict* function from base R.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredictions = predict(lmodel, newdata = testing, type = \"prob\")\nhead(predictions)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n         Bad      Good\n2  0.2547727 0.7452273\n6  0.4854772 0.5145228\n10 0.2040837 0.7959163\n15 0.5020246 0.4979754\n17 0.1683434 0.8316566\n18 0.3710473 0.6289527\n```\n:::\n:::\n\n\n## Model Evaluation and Diagnostics\n\nIs this model any good? How well does it fit our data? Which predictors are the most important?\n\n### 1. Likelihood Ratio Test:\n\nTests whether the full model or a lesser model is the better fit for the data. A smaller p-value provides sufficient evidence that the full model is better than a reduced model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmod_fit_one <- glm(Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + \n                     CreditHistory.Critical,\n                   data=training,\n                   family=\"binomial\")\nmod_fit_two <- glm(Class ~ Age + ForeignWorker,\n                   data=training,\n                   family = binomial(link = \"logit\"))\n\nanova(mod_fit_one, mod_fit_two, test =\"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Deviance Table\n\nModel 1: Class ~ Age + ForeignWorker + Property.RealEstate + Housing.Own + \n    CreditHistory.Critical\nModel 2: Class ~ Age + ForeignWorker\n  Resid. Df Resid. Dev Df Deviance  Pr(>Chi)    \n1       594     691.14                          \n2       597     723.12 -3  -31.976 5.294e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n**Conclusion** The full model is a better fit than a reduced model.\n\n### 2. Pseudo R\\^2\n\nLinear regression has the well-known $R^{2}$. However, logistic regression does not, so we'll use something called McFadden's $R^{2}$, which is given by: $1-\\frac{ln(LM)}{ln(L0)}$ where ln(LM) is the log likelihood value for the fitted model and ln(L0) is the log likelihood for the null model with just the intercept. Values closer to 0 indicate less predictive power and values closer to 1 indicate more predictive power.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pscl)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nClasses and Methods for R developed in the\nPolitical Science Computational Laboratory\nDepartment of Political Science\nStanford University\nSimon Jackman\nhurdle and zeroinfl functions by Achim Zeileis\n```\n:::\n\n```{.r .cell-code}\npR2(mod_fit_one)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfitting null model for pseudo-r2\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n          llh       llhNull            G2      McFadden          r2ML \n-345.57110076 -366.51858123   41.89496095    0.05715257    0.06744294 \n         r2CU \n   0.09562580 \n```\n:::\n:::\n\n\nThe output above indicates that are model has low predictive power\n\n### 3. Hosmer-Lemeshow Test\n\nThis test examines whether the proportion of events are similar to the predicted probabilities of occurrence in subgroups of the data using a chi-square test. **Interpretation:** Small values with large p-values indicate a good fit to the data while large values with p-values below 0.05 indicate a poor fit. Null hypothesis: the model fits the data\n\n### 4. Variable Importance\n\nMeasures the absolute value of the t-statistic for each model parameter\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvarImp(lmodel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nglm variable importance\n\n                       Overall\nCreditHistory.Critical  100.00\nHousing.Own              69.35\nProperty.RealEstate      59.15\nForeignWorker            28.81\nAge                       0.00\n```\n:::\n:::\n\n\n### 5. Confusion Matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\npreds = predict(lmodel, newdata = testing)\nconfusionMatrix(data = preds, reference = testing$Class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Bad Good\n      Bad   12   15\n      Good 108  265\n                                          \n               Accuracy : 0.6925          \n                 95% CI : (0.6447, 0.7374)\n    No Information Rate : 0.7             \n    P-Value [Acc > NIR] : 0.651           \n                                          \n                  Kappa : 0.0596          \n                                          \n Mcnemar's Test P-Value : <2e-16          \n                                          \n            Sensitivity : 0.1000          \n            Specificity : 0.9464          \n         Pos Pred Value : 0.4444          \n         Neg Pred Value : 0.7105          \n             Prevalence : 0.3000          \n         Detection Rate : 0.0300          \n   Detection Prevalence : 0.0675          \n      Balanced Accuracy : 0.5232          \n                                          \n       'Positive' Class : Bad             \n                                          \n```\n:::\n:::\n\n\n# Probit Regression:\n\n$E(Y|X) = P(Y=1|X)$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmyprobit <- glm(admit ~ gre + gpa + rank,\n                family = binomial(link = \"probit\"),\n                data = mydata)\nsummary(myprobit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = admit ~ gre + gpa + rank, family = binomial(link = \"probit\"), \n    data = mydata)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.6163  -0.8710  -0.6389   1.1560   2.1035  \n\nCoefficients:\n             Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -2.386836   0.673946  -3.542 0.000398 ***\ngre          0.001376   0.000650   2.116 0.034329 *  \ngpa          0.477730   0.197197   2.423 0.015410 *  \nrank2       -0.415399   0.194977  -2.131 0.033130 *  \nrank3       -0.812138   0.208358  -3.898 9.71e-05 ***\nrank4       -0.935899   0.245272  -3.816 0.000136 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 499.98  on 399  degrees of freedom\nResidual deviance: 458.41  on 394  degrees of freedom\nAIC: 470.41\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\nAs is evident, all model terms are statistically significant at $\\alpha = 0.05$\n\nTo interpret the probit coefficients and output:\n\n-   For a one unit increase in **gre**, the z-score of admission increases by 0.001.\n-   For a one unit increase in **gpa**, the z-score of admission increases by 0.478. \\*Attending a rank 2 school decreases the z-score of admission by 0.4154 compared to a rank 1 school.\n-   Null deviance represents the difference between a full model and a model with just the y-intercept as a coefficient. The goal is for the model to have a low residual deviance.\n",
    "supporting": [
      "logregcaret_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}